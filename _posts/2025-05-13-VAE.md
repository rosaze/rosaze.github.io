---
layout: post
title: "Auto-Encoding Variational Bayes"
date: 2025-05-13
categories: [cv-nlp-pe] # 또는 [research, nlp] 또는 [research, computer-vision]
use_math: true
---

### [논문 링크](https://arxiv.org/abs/1312.6114)

# VAE (Variational Auto Encoder)

### generation with Neural Networks

inputs: Pixel level. -> 원하는 인풋 픽셀이 특정 이미지를 만들 수 있도록 Generative Neural Networks 설계. -/

**Generative Neural Networks**

- Inputs이 예시로 pixel level일때 고해상도 -> 학습이 어렵다 (예측하기 어렵다)
<p style="text-align: center;">따라서</p>
- inputs: 데이터 안에 숨어있는 변수들 . latent variable(high level description)
  **latent variable 의 pros**
- only train low dimension information -> easy to estimate
- can control the generative process
  즉 Generative Neural networks 의 목표는 데이터셋에 있을법한 잠재 변수들을 하나하나 매핑하는 것. GMM 에서는 아예 정의를 하고 시작했지만 ,뉴럴 네트워크는 빅데이터에 있는잠재 변수들을 학습을 통해 찾아내는 것.머신러닝 기반의 생성모델보다 훨씬 더 데이터를 잘 찾아냄. "찾고 -> 생성한다" 매핑은 잘 찾아진 데이터를 각각의 타겟 도메인에 맞게 생성을 한다. 네트워크를 학습을 한다.

_ input data 를 잘 나타낼 수 있는 latent variable를 어떻게 잘 찾을건가?_

gan 이이랑 vae 차이. diffusion dms vae 랑 거의 똑같ㅇㅁ .vae는 한 스텝만에 찾는데 디퓨전은 이걸 1000번을 함 -> 우리가 알고있는 gaussian 으로 함. 각 프로세슷를 이해할떄 latent var을 어떻게 찾는지.

in terms of Encoder
**AutoEncoder**: explore the latent variable as deterministic (일대일로 매핑) code .
**variational autoencoder**: explore the latent variable as stochastic (확률적으로 매핑) code.확률저그로 샘플링 된 형태로 만들어진다. 왜 autoencoder가 생성형이 아니지 ? . 차이점은decoder 가 아니라 encoder에 있음 .

in terms of decoder

- mapping function from latent variable to output data -> Autoencoder= variaitional autoencoder

### AutoEncoder

Autoencoder = Encoder + Decoder

- Autoencoder는 입력 데이터를 잠재 공간(latent space)으로 압축했다가 다시 복원하는 신경망 구조이다. 비지도 학습에 사용되며, 입력과 출력이 동일한 형태를 가진다.
- neural networks for compressing and reconstructing data.
  train encoder and decoder with reconstruction loss(MSE loss)
  데이터를 z 로 압축하고 암축된 데이터로부터 원래 데이터를 복원한다.
  encoder: 잘 대표할수 있는 특징들로 잠재변수 z로 압축.

<div style="background-color:rgba(100, 92, 247, 0.23); padding: 20px; border-radius: 10px;">
  <h3 style="margin-top: 0;">구성</h3>
  <p>Autoencoder는 다음과 같이 구성된다:<br>

- $Encoder Q(x)$ : 입력 x를 잠재 변수 z로 인코딩 <br>
- $Decoder P(z)$: 잠재 변수 z를 원래 입력과 비슷한 y로 디코딩<br>
- $Loss$: 입출력의 차이를 최소화하는 재구성 손실 사용</p>
<p>

$x \in \mathbb{R}^n \quad \text{(입력 데이터)}$
$z = Q(x) \in \mathbb{R}^d \quad \text{(잠재 표현, \( d < n \))}$
$y = P(z) = P(Q(x)) \quad \text{(복원된 출력)}$

<hr>
손실함수: $\mathcal{L}_{AE} = \sum_{x \in D} \mathcal{L}(x, y) = \sum_{x \in D} \mathcal{L}(x, P(Q(x)))$
<br>가장 일반적으로 사용하는 손실 함수는 -> MSE이다.
$\mathcal{L}_{\text{reconstruction}}(x, y) = \|x - y\|^2$

</p>
</div>

**encoder**

- 예시:
  - 입력 이미지가 예를 들어 256x256x3(가로 256, 세로 256, RGB 3채널) 짜리
  - 이걸 **잠재 공간(latent space)**의 아주 작은 벡터, 예를 들어 1x2 크기로 압축. 고차원 데이터를 저차원 벡터로 "압축"하는 역할을 하는 네트워크가 바로 **인코더(encoder)**
  - 이미지라면 **CNN (Convolutional Neural Network)**을 주로 써서 인코더를 구성하고, 오디오나 시퀀스 데이터면 **RNN (Recurrent Neural Network)**을 쓰기
- 예시:
  - 이미지를 인코더에 넣으면 바로 잠재 벡터 z가 나옴.
  - 각각은 deterministic. : x를 넣으면 항상 같은 z가 나온다는 뜻이야. (확률적이 아니라 확정적)
  - 중요: **실제로는 latent variable 의 값의 의미를 알 수 는 없다.**

**decoder:**: (z를 받아서 원래의 x처럼 보이게) 원래 이미지로 복원하는 네트워크 . 학습이 잘 되면, P(z)가 x랑 거의 똑같아지도록 RECONSTRUCT 가능

```text
x (256x256x3) ─▶ Encoder ─▶ z (1x2) ─▶ Decoder ─▶ y (복원된 이미지)
```
