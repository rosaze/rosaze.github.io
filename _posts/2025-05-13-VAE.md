---
layout: post
title: "Auto-Encoding Variational Bayes"
date: 2025-05-13
categories: [cv-nlp-pe] # 또는 [research, nlp] 또는 [research, computer-vision]
use_math: true
---

### [논문 링크](https://arxiv.org/abs/1312.6114)

# VAE (Variational Auto Encoder)

### generation with Neural Networks

inputs: Pixel level. -> 원하는 인풋 픽셀이 특정 이미지를 만들 수 있도록 Generative Neural Networks 설계. -/

**Generative Neural Networks**

- Inputs이 예시로 pixel level일때 고해상도 -> 학습이 어렵다 (예측하기 어렵다)
<p style="text-align: center;">따라서</p>
- inputs: 데이터 안에 숨어있는 변수들 . latent variable(high level description)
  **latent variable 의 pros**
- only train low dimension information -> easy to estimate
- can control the generative process
  즉 Generative Neural networks 의 목표는 데이터셋에 있을법한 잠재 변수들을 하나하나 매핑하는 것. GMM 에서는 아예 정의를 하고 시작했지만 ,뉴럴 네트워크는 빅데이터에 있는잠재 변수들을 학습을 통해 찾아내는 것.머신러닝 기반의 생성모델보다 훨씬 더 데이터를 잘 찾아냄. "찾고 -> 생성한다" 매핑은 잘 찾아진 데이터를 각각의 타겟 도메인에 맞게 생성을 한다. 네트워크를 학습을 한다.

_ input data 를 잘 나타낼 수 있는 latent variable를 어떻게 잘 찾을건가?_

gan 이이랑 vae 차이. diffusion dms vae 랑 거의 똑같ㅇㅁ .vae는 한 스텝만에 찾는데 디퓨전은 이걸 1000번을 함 -> 우리가 알고있는 gaussian 으로 함. 각 프로세슷를 이해할떄 latent var을 어떻게 찾는지.

in terms of Encoder
**AutoEncoder**: explore the latent variable as deterministic (일대일로 매핑) code .
**variational autoencoder**: explore the latent variable as stochastic (확률적으로 매핑) code.확률저그로 샘플링 된 형태로 만들어진다. 왜 autoencoder가 생성형이 아니지 ? . 차이점은decoder 가 아니라 encoder에 있음 .
for building the generative neral networks based on autoencoder

1. we define the latent var

- 인코더로부터 학습을 시키는 것.

2. we embed the input data into the latent space
3. we generate output data from explored latent space

in terms of decoder

- mapping function from latent variable to output data -> Autoencoder= variaitional autoencoder

## AutoEncoder

Autoencoder = Encoder + Decoder

- Autoencoder는 입력 데이터를 잠재 공간(latent space)으로 압축했다가 다시 복원하는 신경망 구조이다. 비지도 학습에 사용되며, 입력과 출력이 동일한 형태를 가진다.
- neural networks for compressing and reconstructing data.
  train encoder and decoder with reconstruction loss(MSE loss)
  데이터를 z 로 압축하고 암축된 데이터로부터 원래 데이터를 복원한다.
  encoder: 잘 대표할수 있는 특징들로 잠재변수 z로 압축.

<div style="background-color:rgba(100, 92, 247, 0.23); padding: 20px; border-radius: 10px;">
  <h3 style="margin-top: 0;">구성</h3>
  <p>Autoencoder는 다음과 같이 구성된다:<br>

- $Encoder Q(x)$ : 입력 x를 잠재 변수 z로 인코딩 <br>
- $Decoder P(z)$: 잠재 변수 z를 원래 입력과 비슷한 y로 디코딩<br>
- $Loss$: 입출력의 차이를 최소화하는 재구성 손실 사용</p>
<p>

$x \in \mathbb{R}^n \quad \text{(입력 데이터)}$
$z = Q(x) \in \mathbb{R}^d \quad \text{(잠재 표현, \( d < n \))}$
$y = P(z) = P(Q(x)) \quad \text{(복원된 출력)}$

<hr>
손실함수: $\mathcal{L}_{AE} = \sum_{x \in D} \mathcal{L}(x, y) = \sum_{x \in D} \mathcal{L}(x, P(Q(x)))$
<br>가장 일반적으로 사용하는 손실 함수는 -> MSE이다.
$\mathcal{L}_{\text{reconstruction}}(x, y) = \|x - y\|^2$

</p>
</div>

**encoder**

- 예시:
  - 입력 이미지가 예를 들어 256x256x3(가로 256, 세로 256, RGB 3채널) 짜리
  - 이걸 **잠재 공간(latent space)**의 아주 작은 벡터, 예를 들어 1x2 크기로 압축. 고차원 데이터를 저차원 벡터로 "압축"하는 역할을 하는 네트워크가 바로 **인코더(encoder)**
  - 이미지라면 **CNN (Convolutional Neural Network)**을 주로 써서 인코더를 구성하고, 오디오나 시퀀스 데이터면 **RNN (Recurrent Neural Network)**을 쓰기
- 예시:
  - 이미지를 인코더에 넣으면 바로 잠재 벡터 z가 나옴.
  - 각각은 deterministic. : x를 넣으면 항상 같은 z가 나온다는 뜻.(확률적이 아니라 확정적)
  - 중요: **실제로는 latent variable 의 값의 의미를 알 수 는 없다.**

**decoder:**
(z를 받아서 원래의 x처럼 보이게) 원래 이미지로 복원하는 네트워크 . 학습이 잘 되면, P(z)가 x랑 거의 똑같아지도록 RECONSTRUCT 가능

```text
x (256x256x3) ─▶ Encoder ─▶ z (1x2) ─▶ Decoder ─▶ y (복원된 이미지)
```

### Autoencoder is not a generative model. WHY?

픽셀 대응이 1:1 레벨일때 단점
고해상도일수록 학습도 어렵고, 생성도 어렵다
컨트롤이 어렵다. 매핑이 어렵다 .
위 두 단점을 latent var 을 ㅇㅇ 함으로써 해결.
**goal of generative neural networks**

1. latent variable 이 input data 를 잘 나타내도록 탐색해야 한다.
2. train the generative neural networks to synthesize the output data. 원래 데이터 잘 찾기.

→ **입력 데이터 없이 latent variable z를 정의할 수 없기 때문.**
→ **즉, z는 반드시 입력 데이터 x를 통해서만 얻을 수 있음.**

z는 입력 x에서 항상 같은 값으로 압축된다.
→ 즉, z는 고정된 값 (deterministic)
→ 그래서 출력 y는 항상 입력 x와 같음 (그저 복원하는 것뿐)

Autoencoder는 주로 차원 축소(compression) 용도
→ 예: PCA와 유사한 역할

\*\*But VAE (Variational Autoencoder)는 다르다\*\*

- VAE는 input data 없어도 latent variable 를 정의할 수 있다면, 생성모델을 뉴럴 네트워크를 통해 빌딩할 수 있음.즉, z가 어떤 분포(예: 정규분포)를 따른다고 정의만 하면, 샘플링을 통해 데이터를 생성할 수 있음.

수학적으로 데이터를 보지 않고는 의미 있는 z를 정의할 수 없음.
→ 그래서 인코더가 필요함: 입력 데이터 분포를 보고 z가 어떤 분포를 따라야 할지 학습함. 즉, 데이터와 latent variable 간의 연관성을 만들어 주는 게 인코더의 역할

- 디코더는 latent variable z를 받아서 원래 입력 데이터 x를 복원하려는 역할을 한다.Autoencoder와 VAE 모두 디코더는 입력과 유사한 출력을 만들어내지만, z의 성격이 완전히 다르다.

## Variational Autoencoder

latent variable as stochastic code

autoencoder는 그냥 압축시킨 것으로, 차원을 정의할 수 없다. 반면 VAE의 latent space에서는 각 포인트가 하나의 Gaussian 분포로 표현된다.
이는 단순히 데이터를 압축하는 것을 넘어서, 새로운 데이터를 생성할 수 있게 해주는 기반이 된다.즉, VAE는 차원 축소를 하면서도 확률적 분포를 학습하여 생성 가능성을 확보한다.

- variational: 변분. 어떤 함수의 형태를 조금씩 변화시키면서 , 그 결과가 최적이 되는 조건을 찾는 방법. **vae는 데이터의 복잡한 분포를 단순한 분포로 근사하는 모델**
- 한 스텝 만에 근사
- 복잡한 분포 -> 인코더 -> 정의할수있는 분포(근사 )

---

**For Building the generative neural networks based on Autoencoder**

### 1. (stochastic) latent variable 정의

우리는 latent variable `z`가 **정규분포(Gaussian distribution)** 에서 샘플링된다고 가정할 수 있다.

- 즉, 수학적으로 `z ~ N(0, I)` 와 같은 방식으로 정의된다.

### 2. embed the input data into the latent space

무작위 Gaussian 분포만으로는 실제 학습 데이터의 분포를 잘 표현할 수 없다.

- 따라서, **Encoder 네트워크**를 학습하여 입력 데이터를 latent space에 잘 맞는 Gaussian 분포로 **근사**하게 한다.
- Encoder는 입력 데이터를 통해 Gaussian 분포의 **파라미터 `μ`(mean), `σ`(standard deviation)** 를 추정한다. 알아서 loss function을 만들어주면 neural network 가 알아서 찾아줌. weight 들이 알아서 학습해줌.
- 결과적으로, **고차원 입력 데이터를 작은 latent 변수(숨겨진 변수)의 정규분포**로 매핑하는 과정이다.

### 3. generate output data from explored latent space

학습된 latent space에서 `z ~ N(μ, σ)`를 샘플링하고, 이를 **Decoder**에 입력하여 데이터를 생성한다. **새로운 데이터를 생성**하거나, 기존 데이터를 복원하는 데 사용된다.

목표: log P<sub>θ</sub>(x)의 최대화

- 우리가 **실제로 찾고 싶은 것**은 바로 `log Pθ(x)`
- VAE의 학습 목적은 주어진 관측 데이터 `x`에 대한 확률 `Pθ(x)`를 최대화하는 것이다. 하지만 이 확률은 잠재 변수 `z`에 대해 적분된 형태로 주어지므로 직접 계산이 어렵다.

$
\[
P_\theta(x) = \int p_\theta(x \mid z) p(z) \, dz
\]
$

> 따라서, 이를 근사하기 위해 Variational Inference 기법을 적용하여 **Evidence Lower Bound (ELBO)** 를 도입한다.

#### ELBO 유도 과정

임의 분포 $\( q\_\phi(z \mid x) \)$를 도입하여 다음과 같이 전개한다:
<img src="images/lecture/a3.png" alt="고양이" width="700" height="300">

### Variational Autoencoder with code

Model(Encoder,Decoder)

1. 입력 → 잠재 공간 인코딩 $Encoder \( Q(x) \)$

입력 벡터 x 는 Fully Connected Layer (MLP)와 ReLU를 거쳐 잠재 공간(latent space)으로 인코딩된다.

잠재 공간은 정규 분포를 따르며, Encoder는 평균 벡터 $\( \mu \)$와 로그 분산 벡터 $\( \log(\sigma^2) \)$를 출력한다.

샘플링된 z는 reparameterization trick을 통해 다음과 같이 계산된다:
$
\[
z = \mu + \sigma \cdot \epsilon, \quad \epsilon \sim \mathcal{N}(0, 1)
\]
$
샘플링된 z는 다시 MLP와 ReLU를 거쳐 원래 입력과 유사한 y를 복원한다.

Decoder는 $\( P(z) \)$를 통해 $\( x \)$의 분포를 다음과 같이 재구성한다:

$
\[
y \approx \hat{x} = P(z)
\]
$

```python
import torch
import torch.nn as nn
import torch.nn.functional as F

class VAE(nn.Module):
    def __init__(self, input_dim=784, hidden_dim=400, latent_dim=20):
        super(VAE, self).__init__()

        # 🔷 Encoder
        self.fc1 = nn.Linear(input_dim, hidden_dim)             # 입력 x → 은닉 벡터 h
        self.fc_mu = nn.Linear(hidden_dim, latent_dim)          # 은닉 h → 평균 μ
        self.fc_logvar = nn.Linear(hidden_dim, latent_dim)      # 은닉 h → 로그 분산 log(σ²)

        # 🔶 Decoder
        self.fc2 = nn.Linear(latent_dim, hidden_dim)            # z → 은닉 h
        self.fc3 = nn.Linear(hidden_dim, input_dim)             # 은닉 h → 복원된 x

```

다음은 Variational Autoencoder의 학습 루프 일부이다.

```python

# Reconstruction Loss

recon_loss = F.binary_cross_entropy(recon_x, x, reduction='sum')

# KL Divergence

kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())

# ELBO (Negative)

loss = recon_loss + kl_loss
```

이 코드에서 각각의 손실 항이 어떤 의미를 가지는지 설명하시오.
또한 이 손실의 수학적 최종 형태를 식으로 간단히 쓰시오.
